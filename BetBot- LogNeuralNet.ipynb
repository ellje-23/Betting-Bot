{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0179d176-9159-470e-8f2b-e552482a49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58bae22-2128-47bb-a847-416279b7a55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41073, 54)\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('allGames.csv')\n",
    "\n",
    "# Cut off the first 21,294 rows, which include limited stats from before things like rebounds and steals were recorded\n",
    "# All stats tracked in 1985, so we start our data here\n",
    "df = df[21294:]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f41d3d-a760-450c-a952-c6014273dfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41073, 10)\n",
      "(41073,)\n"
     ]
    }
   ],
   "source": [
    "# Select only the numerical attributes\n",
    "# Removed - 'fgm_home', 'fg3m_home', 'ftm_home', 'fgm_away', 'fg3m_away', 'ftm_away', 'pts_away'\n",
    "df_X = df[['reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home', 'reb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away']]\n",
    "df_y = df['wl_home']\n",
    "\n",
    "print(df_X.shape)\n",
    "print(df_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b1b46d-8976-492f-9cf5-0634793cd7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_y of 1 and 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21294    L\n",
       "21295    W\n",
       "21296    L\n",
       "21297    L\n",
       "21298    W\n",
       "        ..\n",
       "62362    W\n",
       "62363    L\n",
       "62364    W\n",
       "62365    L\n",
       "62366    L\n",
       "Name: wl_home, Length: 41073, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the current state of df_y: A column of W and L\n",
    "print(\"df_y of 1 and 0\")\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ebfde5e-11b6-429e-b4e8-5f40c5af0e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_y of 1 and 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21294    0\n",
       "21295    1\n",
       "21296    0\n",
       "21297    0\n",
       "21298    1\n",
       "        ..\n",
       "62362    1\n",
       "62363    0\n",
       "62364    1\n",
       "62365    0\n",
       "62366    0\n",
       "Name: wl_home, Length: 41073, dtype: int32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the W/L strings of df_y to 0's and 1's, where W = 1 and L = 0\n",
    "df_y = (df_y == 'W').astype(int)\n",
    "\n",
    "# Sanity check: A column of 1 and 0 \n",
    "print(\"\\ndf_y of 1 and 0\")\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d32d45dd-ba49-4e80-9cba-7a56cd24bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using Z-score\n",
    "df_X = (df_X - df_X.mean()) / df_X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35729e3b-5139-4d9a-a4c4-632a365a7f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32248, 10)\n",
      "(8824, 10)\n",
      "(32248,)\n",
      "(8824,)\n"
     ]
    }
   ],
   "source": [
    "# Create the training and testing sets \n",
    "# Splitting between 1985-2015, and 2015-2023\n",
    "X_train = df_X.iloc[:32248] \n",
    "X_test = df_X.iloc[32249:]\n",
    "\n",
    "y_train = df_y.iloc[:32248]\n",
    "y_test = df_y.iloc[32249:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f85a239-2b22-48b3-8177-3db93e2d9e31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32248, 10)\n",
      "(32248,)\n",
      "(8824, 10)\n",
      "(8824,)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Verify the data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd2b5e28-f8d5-4c63-9844-fc554b0693d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Evaluation Metrics\n",
      "Training accuracy:  79.23902257504342\n",
      "Testing accuracy:  78.85312783318224\n",
      "\n",
      "Y_test: \n",
      " [1 0 0 0 0 0 0 1 1 0]\n",
      "\n",
      "Y_pred: \n",
      " [1 0 0 0 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Import the logistic regression functionality from scikit-learn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a logistic regression model:\n",
    "model = MLPClassifier(hidden_layer_sizes=(50, 50), activation='logistic', solver='sgd', max_iter=1000)\n",
    "\n",
    "# Train the model on the traing data:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Output the weight vector\n",
    "W_direct = model.coefs_\n",
    "#print(\"Weight vector W:\", W_direct) # 10 values\n",
    "\n",
    "# Predict the output values for the testing data:\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model:\n",
    "print(\"\\nClassification Evaluation Metrics\")\n",
    "print(\"Training accuracy: \", model.score(X_train, y_train) * 100)\n",
    "print(\"Testing accuracy: \", model.score(X_test, y_test) * 100)\n",
    "\n",
    "# Print the first 10 test and predicted values:\n",
    "print()\n",
    "print(\"Y_test: \\n\", y_test[0:10])\n",
    "print()\n",
    "print(\"Y_pred: \\n\", y_pred[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3177b-69a2-4865-a874-a37721122a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
